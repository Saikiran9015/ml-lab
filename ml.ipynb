{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34436de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 20.25\n",
      "Median: 18.5\n",
      "Mode: 13\n",
      "Variance: 66.21428571428571\n",
      "Standard Deviation: 8.137216091163225\n"
     ]
    }
   ],
   "source": [
    "import  statistics as stats\n",
    "def calculate_statistics(data):\n",
    "    mean = stats.mean(data)\n",
    "    median = stats.median(data)\n",
    "    try:\n",
    "        mode = stats.mode(data)\n",
    "    except stats.StatisticsError:\n",
    "        mode = \"No unique mode\"\n",
    "    return mean, median, mode\n",
    "\n",
    "def compute_dispersion(data):\n",
    "    variance = stats.variance(data)\n",
    "    std_dev = stats.stdev(data)\n",
    "    return variance, std_dev\n",
    "\n",
    "def main():\n",
    "    data = [13,14,15,18,19,20,25,38]\n",
    "    mean, median, mode = calculate_statistics(data)\n",
    "    variance, std_dev = compute_dispersion(data)\n",
    "\n",
    "    print(f\"Mean: {mean}\")\n",
    "    print(f\"Median: {median}\")\n",
    "    print(f\"Mode: {mode}\")\n",
    "    print(f\"Variance: {variance}\")\n",
    "    print(f\"Standard Deviation: {std_dev}\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6aac116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  statistics as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ecd439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(data):\n",
    "    mean = stats.mean(data)\n",
    "    median = stats.median(data)\n",
    "    try:\n",
    "        mode = stats.mode(data)\n",
    "    except stats.StatisticsError:\n",
    "        mode = \"No unique mode\"\n",
    "    return mean, median, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3ee65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dispersion(data):\n",
    "    variance = stats.variance(data)\n",
    "    std_dev = stats.stdev(data)\n",
    "    return variance, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf7541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data = [13,14,15,18,19,20,25,38]\n",
    "    mean, median, mode = calculate_statistics(data)\n",
    "    variance, std_dev = compute_dispersion(data)\n",
    "\n",
    "    print(f\"Mean: {mean}\")\n",
    "    print(f\"Median: {median}\")\n",
    "    print(f\"Mode: {mode}\")\n",
    "    print(f\"Variance: {variance}\")\n",
    "    print(f\"Standard Deviation: {std_dev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2390a25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 20.25\n",
      "Median: 18.5\n",
      "Mode: 13\n",
      "Variance: 66.21428571428571\n",
      "Standard Deviation: 8.137216091163225\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188c25c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Study of the python basiec statistics module  maths functions nump and methods sypay in relation to basic statistics calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16519232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Textblob\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nltk>=3.9 (from Textblob)\n",
      "  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in c:\\users\\abbus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk>=3.9->Textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\abbus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk>=3.9->Textblob) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\abbus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk>=3.9->Textblob) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\abbus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk>=3.9->Textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\abbus\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk>=3.9->Textblob) (0.4.6)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 624.3/624.3 kB 1.7 MB/s  0:00:00\n",
      "Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: nltk, Textblob\n",
      "\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   ---------------------------------------- 0/2 [nltk]\n",
      "   -------------------- ------------------- 1/2 [Textblob]\n",
      "   -------------------- ------------------- 1/2 [Textblob]\n",
      "   -------------------- ------------------- 1/2 [Textblob]\n",
      "   -------------------- ------------------- 1/2 [Textblob]\n",
      "   -------------------- ------------------- 1/2 [Textblob]\n",
      "   -------------------- ------------------- 1/2 [Textblob]\n",
      "   ---------------------------------------- 2/2 [Textblob]\n",
      "\n",
      "Successfully installed Textblob-0.19.0 nltk-3.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f8cfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9907735982966643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abbus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df=pd.read_csv(r\"C:\\Users\\abbus\\Downloads\\Customer_churn_with_Feedback.csv\")\n",
    "df.head(1)\n",
    "\n",
    "\n",
    "df['Churn'].isna().sum()\n",
    "\n",
    "\n",
    "df.loc[df['tenure']<=30, 'Churn']='No'\n",
    "df.loc[df['tenure']>30, 'Churn']='Yes'\n",
    "\n",
    "\n",
    "df[['tenure','Churn']].head(10)\n",
    "\n",
    "\n",
    "df.drop(['PhoneService','OnlineSecurity','MultipleLines','PaperlessBilling','InternetService','SeniorCitizen','DeviceProtection','TechSupport','StreamingMovies','TotalCharges','Contract','PaymentMethod','OnlineBackup','StreamingTV','MonthlyCharges','Partner','gender'],axis=1)\n",
    "\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(Feedback):\n",
    "    polarity = TextBlob(Feedback).sentiment.polarity\n",
    "    if polarity > 0:\n",
    "        return 1 # Positive\n",
    "    elif polarity < 0:\n",
    "        return 0# Negative\n",
    "    else:\n",
    "        return 1  # Neutral treated as Positive (or 0)\n",
    "    \n",
    "\n",
    "\n",
    "negative_words = [\"issue\", \"issues\", \"problem\", \"slow\", \"disconnect\", \"dropped call\", \"network down\"]\n",
    "positive_words = [\"good\", \"excellent\", \"fast\", \"reliable\", \"love\"]\n",
    "\n",
    "def label_feedback(Feedback):\n",
    "    feedback_lower = Feedback.lower()\n",
    "    if any(word in feedback_lower for word in negative_words):\n",
    "        return 0\n",
    "    elif any(word in feedback_lower for word in positive_words):\n",
    "        return 1\n",
    "    else:\n",
    "        return 1  # Treat neutral as positive\n",
    "\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "def label_feedback_combined(feedback):\n",
    "    feedback_lower = feedback.lower()\n",
    "    \n",
    "    if any(word in feedback_lower for word in negative_words):\n",
    "        return 0\n",
    "    elif any(word in feedback_lower for word in positive_words):\n",
    "        return 1\n",
    "    else:\n",
    "        polarity = TextBlob(feedback).sentiment.polarity\n",
    "        return 1 if polarity >= 0 else 0\n",
    "\n",
    "\n",
    "df['feedback_num']=df['Feedback'].apply(label_feedback_combined)\n",
    "\n",
    "\n",
    "\n",
    "def assign_discount(row):\n",
    "    # Condition: last purchase more than 30 days ago\n",
    "    if row['tenure'] > 30:\n",
    "        # Positive feedback → 20% discount\n",
    "        if row['feedback_num'] == 1:\n",
    "            return 0.20\n",
    "        # Negative feedback → 50% discount\n",
    "        elif row['feedback_num'] == 0:\n",
    "            return 0.50\n",
    "    # Otherwise no discount\n",
    "    return 0.0\n",
    "\n",
    "df['discount'] = df.apply(assign_discount, axis=1)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Features (X) and target (y)\n",
    "x = df.drop(['Churn' ,'customerID','tenure'],axis=1)# add more features here if you have\n",
    "y = df['Churn']\n",
    "\n",
    "# 2. Train‑test split (80% train, 20% test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. Train logistic regression\n",
    "model = LogisticRegression(max_iter=1000,random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# 5. Predict on test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# 6. Accuracy and other metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)\n",
    "\n",
    "\n",
    "\n",
    "import pickle \n",
    "pickle.dump(model, open('churn_model.pkl','wb'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
